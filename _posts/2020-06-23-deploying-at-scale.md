Some things I've learned as a team lead of the Pivotal Web Service team (PWS)

PWS is a subscription-based, multi-tenant, Platform-as-a-Serivce Cloud Foundry deployment on AWS.  It comes with components such as Healthwatch, mysql, concourse, service brokers, logsearch, and wavefront nozzle and proxy.  The problem that we are trying to solve is improving automation, monitoring reliability at scale, and creating a feedback loop to R&D.

We were able to support 17k App instances, 5k active orgs, 384k active users using 240 Diego cells, 20 Cloud Controller API instances, 12 router instances, 100 subnets, 650 dedicated MySql service instances, 140 on-demand Redis service instances, for a total of 1440 VMs.  The throughputs are 102k requests/min on the router, 3k requests/min on CAPI, and 9.5k requests/min on UAA. Wavefront metrics ingestion rate is about 32k points/sec.

Some of the best practices that we've developed as a team is grouping Diego cells into cellblocks, this allows deploying specific features to a subset of the cell and allow easy roll back if they cause a problem.  Compared to the release engineering team, where VMs are spinned up from scratch to test fresh install or upgrades, our deployment of long running VMs is more similar to the enterprise-level customers, and can catch different type of issues.

Over time, we have developed some team practices to describe division of responsibilities and adjust continuously to adapt to specific needs, this also applies to incident response practice - ours is influenced by [Incident Command for IT--What We've Learned from the Fire Department](https://www.usenix.org/conference/srecon18americas/presentation/chapman).  We have a
detailed deployment checklist (19 total items), and uses a pipeline to trigger a deploy.  The deploy is a two-step process, first is a manual trigger that generates a report of changes, which will be broadcast to the organization, and then trigger the actual deployment.  We automate as much as of the process as possible, including generating stories for other teams in pivotal tracker, deployment smaller internal deployments, and pick up the latest releases.

One of the most challenging task, which is a benefit to the PWS users, is our certificate rotation.  Cloud Foundry manages a huge amount of certificate and we choose to rotate manually, which involves running a regenerate command and triggering a pipeline.  We have also created an internal tool to scan through CredHub for expiring certificates and automatically add them to our pivotal tracker. This way we can rotate certificate once every few quarters in a large batch.

As you can see, there are tons of metrics that we collect, and we will have a problem of metrics overload than metrics starvation.  How do we select the appropriate metrics to monitor will deserve another post, but fundamentally we focus on SLI/SLO and build our dashboard to notify us of warnings or violations as we are approaching the limit or if we are burning out of our error budget.  The two SLIs we monitor are "CF Push" and "App Availability".  CF Push is monitored with a black-box test running the cf push command on a small app.  We are aiming at a 99.5% success over a 28-day rolling window.  App Availbility is a synthetic check running as an AWS lambda.  It monitors a group of 40 apps and reports whether all are pingable.
